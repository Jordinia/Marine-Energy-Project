{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "pgzWDWnpMjdp",
    "outputId": "6f756b15-4f73-470f-c6c5-27c07840d42b",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Q9j_XuEOMn-U"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 00:40:33.623976: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-22 00:40:33.624003: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-22 00:40:33.624909: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-22 00:40:33.629639: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-22 00:40:34.109600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Concatenate, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 00:40:34.488786: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 00:40:34.502278: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-22 00:40:34.502471: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "id": "w4-8MIJtNfdC",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "# data_path = '/content/drive/MyDrive/merged_weather_marine_data.csv'\n",
    "# data=pd.read_csv(data_path)\n",
    "\n",
    "#data_path = './Weather-Dataset/merged_weather_marine_data.csv'\n",
    "# ini yg bener\n",
    "data_path = './Weather-Dataset/sail_decision_2021-2024.csv'\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFWjg2MpN2RT",
    "outputId": "40e1db85-6485-41de-a4ca-c3c3feecd76c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['temperature_2m (°C)', 'relative_humidity_2m (%)', 'dew_point_2m (°C)',\n",
      "       'apparent_temperature (°C)', 'precipitation (mm)', 'rain (mm)',\n",
      "       'weather_code (wmo code)', 'pressure_msl (hPa)', 'cloud_cover (%)',\n",
      "       'wind_speed_100m (km/h)', 'wind_direction_100m (°)',\n",
      "       'wind_gusts_10m (km/h)', 'is_day ()', 'direct_radiation (W/m²)',\n",
      "       'daily_weather_code (wmo code)', 'wave_height (m)',\n",
      "       'wave_direction (°)', 'wave_period (s)', 'wind_wave_height (m)',\n",
      "       'wind_wave_direction (°)', 'wind_wave_period (s)',\n",
      "       'wind_wave_peak_period (s)', 'swell_wave_height (m)',\n",
      "       'swell_wave_direction (°)', 'swell_wave_period (s)',\n",
      "       'swell_wave_peak_period (s)', 'ocean_current_velocity (km/h)',\n",
      "       'ocean_current_direction (°)', 'sailing_decision'],\n",
      "      dtype='object')\n",
      "(12521, 29)\n"
     ]
    }
   ],
   "source": [
    "# #Cleaning and Preprocessing\n",
    "# print(data.describe())\n",
    "\n",
    "# #column temperature (min, max, avg), precipitation, snow, wind(speed, direction, peak gust), pressure, sunshine duration\n",
    "# print(data.columns)\n",
    "\n",
    "# #melihat info descriptive statistic\n",
    "# print(data.describe())\n",
    "\n",
    "# #melihat banyaknya missing value\n",
    "# print(data.isnull().sum())\n",
    "\n",
    "# #melihat banyaknya entri unique\n",
    "# print(data.nunique())\n",
    "\n",
    "# Menentukan kolom-kolom yang bertipe object\n",
    "object_cols = data.select_dtypes(include=['object']).columns\n",
    "df = data.drop(columns=object_cols)\n",
    "\n",
    "df = df.dropna()   #58 row is dropped\n",
    "#df['sail_decision'] = 1\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNjmBa8nOIx_",
    "outputId": "331c8976-1618-44f1-d8c9-2181b0bb2e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12495, 20, 29)\n",
      "(12495, 7, 29)\n",
      "(8746, 20, 29)\n",
      "(3749, 20, 29)\n",
      "(8746, 7, 29)\n",
      "(3749, 7, 29)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Parameters\n",
    "steps = 20\n",
    "predict_steps = 7\n",
    "\n",
    "# Create sequences\n",
    "inp = []\n",
    "out = []\n",
    "for i in range(len(data_scaled) - (steps + predict_steps - 1)):\n",
    "    inp.append(data_scaled[i:i+steps])\n",
    "    out.append(data_scaled[i+steps:i+steps+predict_steps])\n",
    "\n",
    "inp = np.asarray(inp)\n",
    "out = np.asarray(out)\n",
    "\n",
    "print(inp.shape)  # (n_samples, steps, n_features)\n",
    "print(out.shape)  # (n_samples, predict_steps, n_features)\n",
    "\n",
    "train_test_ratio = 0.7\n",
    "train_size = int(train_test_ratio * inp.shape[0])\n",
    "\n",
    "# Split data\n",
    "x_train_tseries = inp[:train_size, :, :]\n",
    "x_test_tseries = inp[train_size:, :, :]\n",
    "y_train_tseries = out[:train_size, :, :]\n",
    "y_test_tseries = out[train_size:, :, :]\n",
    "\n",
    "print(x_train_tseries.shape)\n",
    "print(x_test_tseries.shape)\n",
    "print(y_train_tseries.shape)\n",
    "print(y_test_tseries.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uf6AnSK6gMrl"
   },
   "source": [
    "**Non seq2seq without static data, output only binary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "l4MCjmqLgS-7",
    "outputId": "322a21ac-6ba2-45d6-f087-98f9f17344df"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Hyperparameters\n",
    "# num_samples = x_train_tseries.shape[0]\n",
    "# input_seq_len = x_train_tseries.shape[1]\n",
    "# num_features = x_train_tseries.shape[2]\n",
    "# target_seq_len = y_train_tseries.shape[1]#y_train.shape[1]  # Number of steps to predict\n",
    "# latent_dim = 32  # Dimension of the latent space\n",
    "\n",
    "# # input_seq_len = 10\n",
    "# # num_features = 20\n",
    "# # target_seq_len = 8  # Number of steps to predict\n",
    "# # latent_dim = 64  # Dimension of the latent space\n",
    "\n",
    "# # Example data preparation, bagian ini nanti diganti jadi data tseries\n",
    "# # x_train = np.random.rand(1000, 10, num_features)  # 1000 samples, 10 time steps, num_features features\n",
    "# # y_train = np.random.rand(1000, 7, num_features)   # 1000 samples, 7 time steps, num_features features\n",
    "# # x_train_static = np.random.rand(1000, 5)          # 1000 samples, 5 static features\n",
    "# y_train_binary = np.random.randint(0, 2, size=(num_samples, 1))  # 1000 samples, binary output\n",
    "\n",
    "# # Define the GRU model\n",
    "# input_seq = Input(shape=(input_seq_len, num_features))\n",
    "# #static_input = Input(shape=(x_train_static.shape[1],))\n",
    "\n",
    "# gru_out = GRU(latent_dim, return_sequences=True)(input_seq)\n",
    "# seq_output = Dense(num_features, activation='linear')(gru_out)\n",
    "\n",
    "# # Flatten the sequence output\n",
    "# flatten_seq = Flatten()(seq_output)\n",
    "\n",
    "# # Concatenate the sequence output with static data\n",
    "# #combined = Concatenate()([flatten_seq, static_input])\n",
    "\n",
    "# # Dense layers for binary classification\n",
    "# x = Dense(64, activation='relu')(flatten_seq)\n",
    "# x = Dense(32, activation='relu')(x)\n",
    "# x = Dense(16, activation='relu')(x)\n",
    "# binary_output = Dense(1, activation='sigmoid', name='binary_output')(x)\n",
    "\n",
    "# # Define and compile the final model\n",
    "# model = Model(inputs=input_seq, outputs=binary_output)\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(x_train_tseries, y_train_binary, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# # Function to predict sequence output and binary classification\n",
    "# def predict_sequence_and_binary(input_seq, model):\n",
    "#     #binary_output = model.predict([input_seq, static_input])\n",
    "#     binary_output = model.predict(input_seq)\n",
    "#     return binary_output\n",
    "\n",
    "# # Example usage\n",
    "# input_seq = x_train_tseries[:1]  # Take the first sample from training data\n",
    "# #static_input = x_train_static[:1]\n",
    "# binary_prediction = predict_sequence_and_binary(input_seq, model)\n",
    "\n",
    "# #print(\"Predicted Sequence:\", predicted_sequence)\n",
    "# print(\"Binary Prediction:\", binary_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1jRSHnZMeLd"
   },
   "source": [
    "**Non Seq2seq with static data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_95YjLG7YTk8",
    "outputId": "9c35772a-8e7c-4fe4-9f8d-011f6288538f"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, GRU, Dense, Concatenate, Flatten, Lambda\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# # Hyperparameters\n",
    "# # input_seq_len = x_train_tseries.shape[1]\n",
    "# # num_features = x_train_tseries.shape[2]\n",
    "# # target_seq_len = y_train.shape[1]  # Number of steps to predict\n",
    "# # latent_dim = 64  # Dimension of the latent space\n",
    "\n",
    "# input_seq_len = 10\n",
    "# num_features = 20\n",
    "# target_seq_len = 10  # Number of steps to predict\n",
    "# latent_dim = 64  # Dimension of the latent space\n",
    "\n",
    "# # Example data preparation  nanti ini diganti sama tseries\n",
    "# x_train = np.random.rand(1000, input_seq_len, num_features)  # 1000 samples, 10 time steps, num_features features\n",
    "# y_train = np.random.rand(1000, target_seq_len, num_features)   # 1000 samples, 10 time steps, num_features features\n",
    "# x_train_static = np.random.rand(1000, 5)          # 1000 samples, 5 static features\n",
    "# y_train_binary = np.random.randint(0, 2, size=(1000, 1))  # 1000 samples, binary output\n",
    "\n",
    "# # Define the GRU model\n",
    "# input_seq = Input(shape=(input_seq_len, num_features))\n",
    "# static_input = Input(shape=(x_train_static.shape[1],))\n",
    "\n",
    "# gru_out = GRU(latent_dim, return_sequences=True)(input_seq)\n",
    "# seq_output = Dense(num_features, activation='linear')(gru_out)\n",
    "\n",
    "# # Flatten the sequence output\n",
    "# flatten_seq = Flatten()(seq_output)\n",
    "\n",
    "# # Concatenate the sequence output with static data\n",
    "# combined = Concatenate()([flatten_seq, static_input])\n",
    "\n",
    "# # Dense layers for binary classification\n",
    "# x = Dense(64, activation='relu')(combined)\n",
    "# x = Dense(32, activation='relu')(x)\n",
    "# binary_output = Dense(1, activation='sigmoid', name='binary_output')(x)\n",
    "\n",
    "# # Define and compile the final model\n",
    "# model = Model(inputs=[input_seq, static_input], outputs=[seq_output, binary_output])\n",
    "# model.compile(optimizer='adam', loss=['mse', 'binary_crossentropy'], metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit([x_train, x_train_static], [y_train, y_train_binary], epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# # Function to predict sequence output and binary classification\n",
    "# def predict_sequence_and_binary(input_seq, static_input, model):\n",
    "#     seq_output, binary_output = model.predict([input_seq, static_input])\n",
    "#     return seq_output, binary_output\n",
    "\n",
    "# # Example usage\n",
    "# input_seq = x_train[:1]  # Take the first sample from training data\n",
    "# static_input = x_train_static[:1]\n",
    "# predicted_sequence, binary_prediction = predict_sequence_and_binary(input_seq, static_input, model)\n",
    "\n",
    "# print(\"Predicted Sequence:\", predicted_sequence)\n",
    "# print(\"Binary Prediction:\", binary_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/serverai/miniconda3/envs/uas-ai/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.26279959082603455\n",
      "Epoch 10, Loss: 0.18308138847351074\n",
      "Epoch 20, Loss: 0.10398118197917938\n",
      "Epoch 30, Loss: 0.0701034665107727\n",
      "Epoch 40, Loss: 0.06005416065454483\n",
      "Epoch 50, Loss: 0.05736932158470154\n",
      "Epoch 60, Loss: 0.05608851835131645\n",
      "Epoch 70, Loss: 0.05459079146385193\n",
      "Epoch 80, Loss: 0.05303611978888512\n",
      "Epoch 90, Loss: 0.05120495706796646\n",
      "Epoch 100, Loss: 0.049226753413677216\n",
      "Epoch 110, Loss: 0.0474223718047142\n",
      "Epoch 120, Loss: 0.04587361589074135\n",
      "Epoch 130, Loss: 0.044525180011987686\n",
      "Epoch 140, Loss: 0.04332662746310234\n",
      "Epoch 150, Loss: 0.04219735041260719\n",
      "Epoch 160, Loss: 0.041072096675634384\n",
      "Epoch 170, Loss: 0.03991403058171272\n",
      "Epoch 180, Loss: 0.0387098528444767\n",
      "Epoch 190, Loss: 0.037454430013895035\n",
      "Test Loss: 0.03729638457298279\n",
      "Test MAE: 0.13778962194919586\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.2):\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "    def forward(self, input_seq, hidden=None):\n",
    "        output, hidden = self.gru(input_seq, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "class DecoderGRU(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, num_layers=1, dropout=0.2):\n",
    "        super(DecoderGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(output_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden):\n",
    "        output, hidden = self.gru(input_seq, hidden)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, target_seq):\n",
    "        encoder_output, encoder_hidden = self.encoder(input_seq)\n",
    "\n",
    "        # Initialize decoder hidden state with encoder final hidden state\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Initialize decoder input with the first element of target_seq\n",
    "        decoder_input = target_seq[:, 0, :].unsqueeze(1)\n",
    "\n",
    "        outputs = []\n",
    "        for t in range(1, target_seq.size(1)):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            outputs.append(decoder_output)\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs\n",
    "\n",
    "# Example usage\n",
    "# input_size = 5\n",
    "# hidden_size = 10\n",
    "# output_size = 3\n",
    "# num_layers = 1\n",
    "# dropout = 0.2\n",
    "\n",
    "x_train_tseries = torch.tensor(x_train_tseries, dtype=torch.float32).to(device)\n",
    "y_train_tseries = torch.tensor(y_train_tseries, dtype=torch.float32).to(device)\n",
    "x_test_tseries = torch.tensor(x_test_tseries, dtype=torch.float32).to(device)\n",
    "y_test_tseries = torch.tensor(y_test_tseries, dtype=torch.float32).to(device)\n",
    "\n",
    "input_size = x_train_tseries.shape[2]\n",
    "hidden_size = 32\n",
    "output_size = y_train_tseries.shape[2]\n",
    "num_layers = 1\n",
    "dropout = 0.2\n",
    "\n",
    "encoder = EncoderGRU(input_size, hidden_size, num_layers, dropout).to(device)\n",
    "decoder = DecoderGRU(output_size, hidden_size, num_layers, dropout).to(device)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "# # Dummy input and target sequences, nanti ini diganti\n",
    "# input_seq = torch.randn(32, 10, input_size)  # (batch_size, seq_length, input_size)\n",
    "# target_seq = torch.randn(32, 10, output_size)  # (batch_size, seq_length, output_size)\n",
    "\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(x_train_tseries, y_train_tseries)\n",
    "    loss = criterion(outputs, y_train_tseries[:, 1:, :])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(x_test_tseries, y_test_tseries)\n",
    "    test_loss = criterion(test_outputs, y_test_tseries[:, 1:, :])\n",
    "    print(f'Test Loss: {test_loss.item()}')\n",
    "\n",
    "    mae_metric = torchmetrics.MeanAbsoluteError().to(device)\n",
    "    test_mae = mae_metric(test_outputs, y_test_tseries[:, 1:, :])\n",
    "    print(f'Test MAE: {test_mae.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def compare_predictions(input_seq, target_seq, model, num_examples=5, num_features=3):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         predictions = model(input_seq, target_seq)\n",
    "\n",
    "#         for i in range(num_examples):\n",
    "#             plt.figure(figsize=(10, 6))\n",
    "#             for j in range(min(num_features, predictions.size(2))):  # Limit to num_features\n",
    "#                 plt.subplot(num_features, 1, j+1)\n",
    "#                 plt.plot(target_seq[i, :, j].cpu().numpy(), label='True')\n",
    "#                 plt.plot(predictions[i, :, j].cpu().numpy(), label='Predicted')\n",
    "#                 plt.title(f'Feature {j+1}')\n",
    "#                 plt.legend()\n",
    "\n",
    "#             plt.tight_layout()\n",
    "#             plt.show()\n",
    "\n",
    "# # Display comparisons for 3 features\n",
    "# compare_predictions(x_test_tseries, y_test_tseries, model, num_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1XGwXYJZYKOi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
